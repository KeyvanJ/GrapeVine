# -*- coding: utf-8 -*-
"""K1-DMPro.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sKWd1sCc5_MtFnH8hmWvVbne3Xz95_Ss

# **Data Preparation**
"""

import zipfile
import os
import pandas as pd
from sklearn.model_selection import train_test_split
from google.colab import drive
import cv2 as cv
import matplotlib.image as mpimg
import numpy as np
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from keras.models import Sequential, Model
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.model_selection import KFold, StratifiedKFold
from sklearn.model_selection import cross_val_score
from sklearn.datasets import make_classification
import tensorflow as tf
import tensorflow.keras.datasets
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.preprocessing.image import array_to_img
from keras.models import Sequential, Model
from tensorflow.keras import Sequential, layers
from keras.layers import Input, Dense, Activation, Dropout
from keras.layers import Flatten, BatchNormalization
from keras.layers import Convolution2D, MaxPooling3D, AveragePooling2D, GlobalAveragePooling2D, Conv2D, Reshape, UpSampling2D
from keras.applications.imagenet_utils import preprocess_input
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.inception_v3 import InceptionV3
from keras.preprocessing.image import img_to_array

# Importing Dataset

drive.mount('/content/drive')

# Extracting the Dataset

path = zipfile.ZipFile('/content/drive/MyDrive/K1/Grapevine_Leaves_Image_Dataset.zip', 'r')
path.extractall('/tmp')

# Creating Data Frame

df = pd.DataFrame()
df['image'] = os.listdir('/tmp/Grapevine_Leaves_Image_Dataset/Ak') + os.listdir('/tmp/Grapevine_Leaves_Image_Dataset/Ala_Idris') + os.listdir('/tmp/Grapevine_Leaves_Image_Dataset/Buzgulu') + os.listdir('/tmp/Grapevine_Leaves_Image_Dataset/Dimnit') + os.listdir('/tmp/Grapevine_Leaves_Image_Dataset/Nazli')
labels = []
paths = []

for data in df['image']:
  labels.append(data.split(' (')[0])
  paths.append('/tmp/Grapevine_Leaves_Image_Dataset/' + data.split(' (')[0] + '/' + data)


df['label'] = labels
df['path'] = paths

# Splitting Train & Test

train, test = train_test_split(df,  random_state = 95, test_size = 0.2)
train.head()

"""# **Data Augmentation**"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import shutil
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
from keras.applications.vgg19 import preprocess_input
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from tensorflow.keras.applications.vgg19 import VGG19
from keras.layers import Input, Dense, Activation, Dropout
from keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D 
from keras.models import Sequential, Model
from tensorflow.keras.applications import ResNet50
import random
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix, accuracy_score
from sklearn.neural_network import MLPClassifier
from keras.layers import Conv2DTranspose

# Augmenting the Data

idg = ImageDataGenerator(horizontal_flip=True, rotation_range=90, vertical_flip = True, zoom_range=[0.4,1.2], brightness_range=[0.5,1.5], validation_split = 0.2)
trainAug = idg.flow_from_dataframe(train, x_col = 'path' , y_col = 'label',target_size = (360, 360), batch_size = 32,shuffle = False, class_mode = 'categorical', subset = 'training')
valAug = idg.flow_from_dataframe(train, x_col = 'path' , y_col = 'label',target_size = (360, 360), batch_size = 32,shuffle = False, class_mode = 'categorical', subset = 'validation')

# Preparing Test Data

tt = ImageDataGenerator()
testSet = idg.flow_from_dataframe(test, x_col = 'path' , y_col = 'label',target_size = (360, 360), batch_size = 32,shuffle = False, class_mode = 'categorical')

# Resnet50 Training

CNNRES = ResNet50(include_top = False, input_shape = (360,360,3), weights = 'imagenet')
for layer in CNNRES.layers:
    layer.trainable = False

g = GlobalAveragePooling2D()(CNNRES.output)
g_pred = Dense(5, activation='softmax')(g)

# Resnet50 Modeling

ResnetModel = Model(inputs = CNNRES.input, outputs = g_pred)

# Resnet50 Compiling

ResnetModel.compile(loss='categorical_crossentropy', optimizer="adam", metrics=['accuracy'])

# Resnet50 Fitting

ResnetHistoy = ResnetModel.fit(trainAug, validation_data = valAug, epochs = 35)

# Plotting Model Training

plt.figure(figsize=(15,5))
plt.plot(ResnetHistoy.history['accuracy'])
plt.plot(ResnetHistoy.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.show()

# Displaying Training Data

training_accuracy_resnet      = ResnetHistoy.history['accuracy'][-1]
training_loss_resnet          = ResnetHistoy.history['loss'][-1]
validation_accuracy_resnet    = ResnetHistoy.history['val_accuracy'][-1]
validation_loss_resnet        = ResnetHistoy.history['val_loss'][-1]
print("Training Accuracy of ResNet50     :", training_accuracy_resnet )
print("Training Loss of ResNet50         :", training_loss_resnet)
print("Validation Accuracy of ResNet50   :", validation_accuracy_resnet)
print("Validation Loss of ResNet50       :", validation_loss_resnet)

# Generating Confusion Matrix and Classification Report

Y_pred_res = ResnetModel.predict(testSet)
y_pred_res = np.argmax(Y_pred_res, axis=1)
print('Confusion Matrix')
conf_matrix_res = confusion_matrix(testSet.classes, y_pred_res)
cm_res = np.array2string(conf_matrix_res)
print(conf_matrix_res)

"""# **Random Seeding**"""

# Running 10 times for Each Random Seed

Total_Acc = 0

# We copy everything we did from the previous steps and run it all ten times again with random seeds each time

for i in range(10):
  randomseed = random.randint(0,120)
  train, test = train_test_split(df,  random_state = randomseed, test_size = 0.2)
  # Augmenting the Data

  idg = ImageDataGenerator(horizontal_flip=True, rotation_range=90, vertical_flip = True, zoom_range=[0.4,1.2], brightness_range=[0.5,1.5], validation_split = 0.2)
  trainAug = idg.flow_from_dataframe(train, x_col = 'path' , y_col = 'label',target_size = (360, 360), batch_size = 32,shuffle = False, class_mode = 'categorical', subset = 'training')
  valAug = idg.flow_from_dataframe(train, x_col = 'path' , y_col = 'label',target_size = (360, 360), batch_size = 32,shuffle = False, class_mode = 'categorical', subset = 'validation')

  # Preparing Test Data

  tt = ImageDataGenerator()
  testSet = idg.flow_from_dataframe(test, x_col = 'path' , y_col = 'label',target_size = (360, 360), batch_size = 32,shuffle = False, class_mode = 'categorical')

  # ResNet

  CNNRES = ResNet50(include_top = False, input_shape = (360,360,3), weights = 'imagenet')
  for layer in CNNRES.layers:
      layer.trainable = False

  g = GlobalAveragePooling2D()(CNNRES.output)
  g_pred = Dense(5, activation='softmax')(g)

  ResnetModel = Model(inputs = CNNRES.input, outputs = g_pred)

  ResnetModel.compile(loss='categorical_crossentropy', optimizer="adam", metrics=['accuracy'])

  ResnetHistoy = ResnetModel.fit(trainAug, validation_data = valAug, epochs = 10) 

  # Evaluating our Models

  valEval = ResnetModel.evaluate(valAug)
  print("Validation Evaluation Results in :" , valEval)
  testEval = ResnetModel.evaluate(testSet)
  print("Test Evaluation Results in :" , testEval)

  # Displaying Confusion Matrixes

  Y_pred_res = ResnetModel.predict(testSet)
  y_pred_res = np.argmax(Y_pred_res, axis=1)
  print('Confusion Matrix')
  conf_matrix_res = confusion_matrix(testSet.classes, y_pred_res)
  cm_res = np.array2string(conf_matrix_res)
  print(conf_matrix_res)
  print("*******")
  Total_Acc = Total_Acc + testEval[1]


print("Mean Accuracy of our Model with random seeding is: ", Total_Acc/10)

"""# **Dimensionality Reduction AutoEncoder**"""

# Creating Data Arrays

directory = os.listdir('/tmp/Grapevine_Leaves_Image_Dataset/')
labels = {"Ak": 0, "Ala_Idris": 1, "Buzgulu": 2, "Dimnit": 3, "Nazli": 4}

train_data = []
train_labels = []

for folder in directory:
    if folder[0] != 'G':

        files = os.listdir(os.path.join("/tmp/Grapevine_Leaves_Image_Dataset/", folder))
        for filee in files:
            image = mpimg.imread(os.path.join("/tmp/Grapevine_Leaves_Image_Dataset/", folder, filee))

            try:
                resized = cv.resize(image, (320,320), interpolation=cv.INTER_AREA)
                train_data.append(resized)
                train_labels.append(labels[folder])

            except:
                break


train_data = np.array(train_data)
train_labels = np.array(train_labels)
train_labels = train_labels.reshape((-1, 1))

print("Train Data Info:")
print(train_data.shape)

X_train, X_test, Y_train, Y_test = train_test_split(train_data, train_labels, test_size=0.2, shuffle=True, random_state=31)

# Encoder
input = layers.Input(shape=(320, 320, 4))

x = Conv2D(64, (3, 3), activation="relu", padding="same")(input)
x = MaxPooling2D((2, 2), padding="same")(x)
x = Conv2D(32, (3, 3), activation="relu", padding="same")(x)
x = MaxPooling2D((2, 2), padding="same")(x)
x = Conv2D(32, (3, 3), activation="relu", padding="same")(x)
x = MaxPooling2D((2, 2), padding="same")(x)


x = Flatten()(x)

latent_space = Dense(1024)(x)

x = Dense(40*40*16)(latent_space)
x = Reshape(target_shape=(40,40,16))(x)

# Decoder

x = Conv2DTranspose(32, (3, 3), strides=2, activation="relu", padding="same")(x)
x = Conv2DTranspose(32, (3, 3), strides=2, activation="relu", padding="same")(x)
x = Conv2DTranspose(64, (3, 3), strides=2, activation="relu", padding="same")(x)
x = Conv2D(4, (3, 3), activation="sigmoid", padding="same")(x)

# Autoencoder

dra = Model(input, x)
encoder = Model(input, latent_space)
dra.compile(optimizer="adam", loss="binary_crossentropy")

# Autoencoder Info

dra.summary()

# Fitting the Autoencoder

dra.fit(x=X_train,y=X_train,epochs = 5, batch_size = 32, shuffle = True, validation_data = (X_test, X_test))

# Extracting the Encoder's Output 

encoded_train = encoder.predict(X_train)
encoded_test = encoder.predict(X_test)

"""# **MLP**"""

classifier = MLPClassifier(hidden_layer_sizes=(1024,), batch_size=32, verbose=False, early_stopping=True)
classifier.fit(encoded_train, test)

y_pred = classifier.predict(encoded_test)
print(classification_report(tt,y_pred))

tt = []
for a in y_test:
    tt.append(a[0])
tt = np.array(tt)
tt.shape

"""# **K Fold Cross Validation**"""

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

# 10 Fold Cross Validation 

f = 1
kfcv = KFold(n_splits = 10)
accuracy_list = []
loss_list = []
idg = ImageDataGenerator(horizontal_flip=True, rotation_range=90, vertical_flip = True, zoom_range=[0.4,1.2], brightness_range=[0.5,1.5], validation_split = 0.2)



for train_index, val_index in kfcv.split(train):
  training_data = train.iloc[train_index]
  validation_data = train.iloc[val_index]
  trainAug = idg.flow_from_dataframe(train, x_col = 'path' , y_col = 'label',target_size = (511, 511), batch_size = 32,shuffle = False, class_mode = 'categorical', subset = 'training')
  valAug = idg.flow_from_dataframe(train, x_col = 'path' , y_col = 'label',target_size = (511, 511), batch_size = 32,shuffle = False, class_mode = 'categorical', subset = 'validation')
  CNNRES = ResNet50(include_top = False, input_shape = (227,227,3), weights = 'imagenet')

  for layer in CNNRES.layers:
      layer.trainable = False

  g = GlobalAveragePooling2D()(CNNRES.output)
  g_pred = Dense(5, activation='softmax')(g)

  ResnetModel = Model(inputs = CNNRES.input, outputs = g_pred)

  ResnetModel.compile(loss='categorical_crossentropy', optimizer="adam", metrics=['accuracy'])

  ResnetHistoy = ResnetModel.fit(trainAug, validation_data = valAug, epochs = 5) 

  valEval = ResnetModel.evaluate(valAug)

  accuracy_list.append(valEval[1]*100)
  loss_list.append(valEval[0]*100)

  f+=1
  tf.keras.backend.clear_session()

ttt = 0
l = 0
for i in range(10):
  ttt += accuracy_list[i]
  l += loss_list[i]
print("Mean accuracy of K fold cross validation is: ", ttt/10)